{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sattler\n",
    "\n",
    "Dataset: https://www.dropbox.com/sh/4adrgjsee60vcvj/AADJ-hbes1uHg3FE0et69sy5a?dl=1\n",
    "\n",
    "Say we have these files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first handle imports..\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from onice_conversion import NWBConverter\n",
    "from onice_conversion import spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store',\n",
      " '2021-02-26_17-19-12_mouse-0232',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_ADC1.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_ADC2.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_ADC3.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_ADC4.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_ADC5.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_ADC6.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_ADC7.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_ADC8.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_AUX1.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_AUX2.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_AUX3.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH1.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH10.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH11.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH12.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH13.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH14.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH15.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH16.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH17.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH18.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH19.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH2.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH20.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH21.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH22.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH23.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH24.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH25.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH26.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH27.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH28.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH29.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH3.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH30.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH31.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH32.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH4.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH5.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH6.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH7.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH8.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/103_CH9.continuous',\n",
      " '2021-02-26_17-19-12_mouse-0232/Continuous_Data.openephys',\n",
      " '2021-02-26_17-19-12_mouse-0232/TT0.spikes',\n",
      " '2021-02-26_17-19-12_mouse-0232/TT1.spikes',\n",
      " '2021-02-26_17-19-12_mouse-0232/TT2.spikes',\n",
      " '2021-02-26_17-19-12_mouse-0232/TT3.spikes',\n",
      " '2021-02-26_17-19-12_mouse-0232/TT4.spikes',\n",
      " '2021-02-26_17-19-12_mouse-0232/TT5.spikes',\n",
      " '2021-02-26_17-19-12_mouse-0232/TT6.spikes',\n",
      " '2021-02-26_17-19-12_mouse-0232/TT7.spikes',\n",
      " '2021-02-26_17-19-12_mouse-0232/all_channels.events',\n",
      " '2021-02-26_17-19-12_mouse-0232/messages.events',\n",
      " '2021-02-26_17-19-12_mouse-0232/messages_bak.events',\n",
      " '2021-02-26_17-19-12_mouse-0232/notebook.mat',\n",
      " '2021-02-26_17-19-12_mouse-0232/settings.xml',\n",
      " '2021-02-26_17-19-12_mouse-0232/stimlog.txt',\n",
      " 'Sky_mouse-0232_2021-02-26T17_19_10.csv',\n",
      " 'Sky_mouse-0232_2021-02-26T17_19_10.mp4',\n",
      " 'TTL_mouse-0232_2021-02-26T17_19_10.csv']\n"
     ]
    }
   ],
   "source": [
    "# we've symlinked the example data folder to the cwd for this example\n",
    "base_path = Path().cwd()  / '2021-02-26_17-19-10_mouse-0232'\n",
    "\n",
    "data_files = [str(path.relative_to(base_path)) for path in base_path.glob(\"**/*\")]\n",
    "pprint(sorted(data_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Which compose a dataset of\n",
    "\n",
    "* Continuous extracellular ephys data recorded by open ephys\n",
    "* Spikes sorted by Kilosort\n",
    "* Stimulus information from some custom behavioral software\n",
    "* Raw video of the behaving animal.\n",
    "\n",
    "Different parts of the metadata are\n",
    "\n",
    "* Encoded in the file paths\n",
    "* embedded in a .mat file\n",
    "* and a .txt file\n",
    "* and a .csv file\n",
    "\n",
    "We'll use our fancy new tools in three steps:\n",
    "\n",
    "1. Add metadata with NWBConverter.add_metadata\n",
    "2. Add nwb-conversion-tools interfaces to common data formats with .add_interface\n",
    "3. Add base pynwb container types with .add_container\n",
    "\n",
    "The first step is to create our converter object, which will store the abstract representation of our data format and handle the conversion to NWB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = NWBConverter(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Metadata!\n",
    "\n",
    "The first step is to add general file-level metadata about the experiment, the researcher, etc. We can see what fields are available/expected from NWB by default with our converter!\n",
    "\n",
    "It's a little verbose, so for the purpose of keeping this notebook readable we'll just print the names of the 'NWBFile' metadata container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_collection',\n",
       " 'electrodes',\n",
       " 'epoch_tags',\n",
       " 'epochs',\n",
       " 'experiment_description',\n",
       " 'experimenter',\n",
       " 'file_create_date',\n",
       " 'identifier',\n",
       " 'institution',\n",
       " 'invalid_times',\n",
       " 'keywords',\n",
       " 'lab',\n",
       " 'notes',\n",
       " 'pharmacology',\n",
       " 'protocol',\n",
       " 'related_publications',\n",
       " 'session_description',\n",
       " 'session_id',\n",
       " 'session_start_time',\n",
       " 'slices',\n",
       " 'source_script',\n",
       " 'source_script_file_name',\n",
       " 'stimulus_notes',\n",
       " 'subject',\n",
       " 'surgery',\n",
       " 'sweep_table',\n",
       " 'timestamps_reference_time',\n",
       " 'trials',\n",
       " 'units',\n",
       " 'virus']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([field['name'] for field in converter.base_nwb_metadata['NWBFile']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Metadata\n",
    "\n",
    "The simplest metadata is static metadata that you don't expect to change across all instances of this data format. We can call `add_metadata` with a dictionary of static metadata, in this case nested within the ``'NWBFile'`` container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_metadata({\n",
    "    'NWBFile': {\n",
    "        'institution': \"University of Oregon\",\n",
    "        'lab': 'Wehr'\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata from paths - the spec module\n",
    "\n",
    "This package relies heavily on its `.spec` module, which gives us tools to express where data is stored in different forms.\n",
    "\n",
    "One common pattern is to specify some metadata in file and directory names. In this case the subject ID is encoded in several of the paths. We will use that to start adding metadata for the other default container in nwb, ``'Subject'`` which has field names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'date_of_birth',\n",
       " 'description',\n",
       " 'genotype',\n",
       " 'sex',\n",
       " 'species',\n",
       " 'subject_id',\n",
       " 'weight']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([field['name'] for field in converter.base_nwb_metadata['Subject']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Let's use this filename (it doesn't matter which, as long as it will be present in all datasets you're applying this converter to):\n",
    "\n",
    "`Sky_mouse-0232_2021-02-26T17_19_10.csv`\n",
    "\n",
    "The subject id `0232` is embedded, and lucky for us so is the experiment start time! We can specify that to the converter like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_first_spec = spec.Path(\n",
    "    'Sky_mouse-{Subject[subject_id]}_{NWBFile[session_start_time]}.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we replaced the parts of the string we want to parse out with `{bracketed}` terms -- these define what to call the variables we extract. We can give nested names (ie. to conform to the container structure of NWB files) using `[]` square brackets.\n",
    "\n",
    "We can preview what the output of our spec object will look like by calling its `parse` method with the directory to look in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Subject': {'subject_id': '0232'},\n",
       " 'NWBFile': {'session_start_time': '2021-02-26T17_19_10'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_first_spec.parse(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata in Files\n",
    "\n",
    "Another common pattern is to store metadata in one or several structured files, like `.json`, `.csv`, `.mat`, and so on. No prob. A lot of our metadata in this case is located in the `notebook.mat` file. \n",
    "\n",
    "We can use one of our helper functions to preview what's in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'Molly',\n",
       " 'mouseID': '0232',\n",
       " 'Depth': 'unknown',\n",
       " 'datapath': 'Z:\\\\lab\\\\djmaus\\\\Data\\\\Molly',\n",
       " 'activedir': '\\\\\\\\wehrrig4\\\\d\\\\lab\\\\djmaus\\\\Data\\\\Molly\\\\2021-02-26_17-19-10_mouse-0232\\\\2021-02-26_17-19-12_mouse-0232',\n",
       " 'LaserPower': 'unknown',\n",
       " 'mouseDOB': 'age unknown',\n",
       " 'mouseSex': 'sex unknown',\n",
       " 'mouseGenotype': 'genotype unknown',\n",
       " 'Drugs': 'none',\n",
       " 'notes': array([], dtype='<U1'),\n",
       " 'Reinforcement': 'none'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_meta = spec.external_file.load_clean_mat(\n",
    "    list(base_path.glob('**/notebook.mat'))[0]\n",
    ")\n",
    "mat_meta['nb']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add metadata from the file using the `Mat` object, which in this case needs us to specify the `key` separately. Since we don't really care about the rest of the path, it might change, and there should only be one notebook, we can just glob away the rest of the path as well\n",
    "\n",
    "Say for example, we want to get the experimenter's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'Molly'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mat_spec = spec.Mat(\n",
    "    path='**/notebook.mat', # 2 **s mean we can glob recursively\n",
    "    key=\"user\", # hold up on the nested ones for this,\n",
    "    field = ('nb', 'user')\n",
    ")\n",
    "mat_spec.parse(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Interfaces!\n",
    "\n",
    "We have some open ephys data here! It's described by the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Schema for ABCMeta\n",
      "-------------------------\n",
      "{'additionalProperties': True,\n",
      " 'properties': {'folder_path': {'description': 'Path to directory containing '\n",
      "                                               'OpenEphys files.',\n",
      "                                'format': 'directory',\n",
      "                                'type': 'string'}},\n",
      " 'required': ['folder_path'],\n",
      " 'type': 'object'}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "converter.add_interface('recording', 'open_ephys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_interface(\n",
    "    'recording', 'open_ephys',\n",
    "    spec.Glob(\n",
    "        key=\"folder_path\",\n",
    "        format=\"*mouse*\",\n",
    "        only_dirs=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the conversion!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter.run_conversion(nwbfile_path='nwbfile.nwb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
